{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1a3318c8a327>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Парсинг\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mBS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Обработка текста\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuilder_registry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdammit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUnicodeDammit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m from .element import (\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m from bs4.element import (\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mCharsetMetaAttributeValue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mContentMetaAttributeValue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Парсинг\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "# Обработка текста\n",
    "import re\n",
    "from validate_email_address import validate_email\n",
    "from itertools import groupby\n",
    "# Работа с файлами\n",
    "import json\n",
    "import os\n",
    "#Вывод прогресса\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url1 = 'Teplypollipetsk.ru'\n",
    "# url2 = 'http://иномарка46.рф'\n",
    "# url3 = 'www.tochkamira.ru'\n",
    "# print(cheek_url(url1))\n",
    "# print(cheek_url(url2))\n",
    "# print(cheek_url(url3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Работоспособность сайта\n",
    "#Список найденных неправильных протоколов\n",
    "bad_list = ['https','http','hhtp://','hhtps://','hhtps://','hpp:','hpps:','hppt','hppts','htt','htth','htto','htpps','^','httpp',\n",
    "            'httt','ttps']\n",
    "def cheek_url(url):\n",
    "    s = url\n",
    "    # Удаление протоколов из ссылки\n",
    "    for i in bad_list:\n",
    "        s = s.replace(i,'')\n",
    "    # Удаление первого символа из спец символов в списке\n",
    "    while s[0] in ['/','.',';',':',',']:\n",
    "        s = s[1:]\n",
    "    # Удаление последнего символа из спец символов в списке\n",
    "    while s[-1] in ['/','.',';',':',',']:\n",
    "        s = s[:-1]\n",
    "    url = s\n",
    "    s_c = 'bad_url'\n",
    "    \n",
    "    try:\n",
    "        url = f'https://{s}'\n",
    "        # Попытка обратиться к сайту с обновленным защищенным протоклом  \n",
    "        response = requests.get(url,timeout = 60)\n",
    "        s_c = response.status_code\n",
    "        if s_c == 200:\n",
    "            return url, s_c\n",
    "        elif s_c != 'bad_url':\n",
    "            return url, s_c\n",
    "    except:\n",
    "        try:\n",
    "            # Попытка обратиться к сайту с обновленным незащищенным протоклом  \n",
    "            url = f'http://{s}'\n",
    "            response = requests.get(url,timeout = 60)\n",
    "            s_c = response.status_code\n",
    "            if s_c == 200:\n",
    "                return url, s_c\n",
    "            elif s_c != 'bad_url':\n",
    "                return url, s_c\n",
    "        except:\n",
    "            return url, s_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Найти все ссылки на странице \n",
    "def get_all_links(page):\n",
    "    try:\n",
    "        HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0'}\n",
    "        html_text = requests.get(page, headers=HEADERS, timeout = 60).text\n",
    "        soup = BS(html_text)\n",
    "        arr = []\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            l = link['href']\n",
    "\n",
    "            if l.find(\"//\") == -1 :\n",
    "                try:\n",
    "                    if l[0] != \"/\":\n",
    "                       l = page + '/' + l \n",
    "                    else:\n",
    "                        l = page + l\n",
    "                except:\n",
    "                    pass\n",
    "            if l!='':\n",
    "                arr.append(l)\n",
    "        return [el for el, _ in groupby(arr)]\n",
    "    except:\n",
    "        return[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск триггеров в тексте\n",
    "#new_triger_list_pay = ['битное шифрование','платежный шлюз','сбербанк']\n",
    "#triger_list_ord = [\"возврат\",\"брак\",\"обмен\",\"ненадлежащего качества\"]\n",
    "\n",
    "new_triger_list_pay_1 = r'битное шифрование'\n",
    "new_triger_list_pay_2 = r'платежн.{2,3} шлюз.{1,2}|сбербанк.{1,2}'\n",
    "\n",
    "new_triger_pers = r'''обработ.{1,5}персональн.{1,5}данных|политик.{1,5} конфиденциальности|\n",
    "политика и защита персональных данных|политика обработки персональных данных|политика по обработке персональных данных|\n",
    "предоставлена третьим лицам|конфиденциальность|152-фз'''\n",
    "\n",
    "triger_list_ord =r\"возврат|брак|обмен|ненадлежащего качества\"\n",
    "\n",
    "triger_list_transfer = r'переводом на карту|перевод по карте|перевести на карту'\n",
    "\n",
    "def new_find_triggers(text):    \n",
    "    new_trig_list_pay = ''\n",
    "    new_trig_list_pers = ''\n",
    "    trig_list_ord = ''\n",
    "    \n",
    "    new_score_pay = 0\n",
    "    score_ord = 0\n",
    "    new_score_pers = 0\n",
    "    score_transfer = 0\n",
    "    #Оплата\n",
    "    pay_find1 = re.findall(new_triger_list_pay_1,text)\n",
    "    pay_find2 = re.findall(new_triger_list_pay_2,text)\n",
    "    if len(pay_find1) > 0:\n",
    "        new_score_pay = 1\n",
    "        new_trig_list_pay = ' , '.join(str(n) for n in pay_find1 )\n",
    "    elif len(pay_find2) == 2:\n",
    "        new_score_pay = 1\n",
    "        new_trig_list_pay = ' , '.join(str(n) for n in pay_find2 )\n",
    "    #персональные данные    \n",
    "    pers_find = re.findall(new_triger_pers,text)    \n",
    "    if len(pers_find) > 0:\n",
    "        new_score_pers = 1\n",
    "        new_trig_list_pers = ' , '.join(str(n) for n in pers_find )\n",
    "    #Заказ\n",
    "    ord_find = re.findall(triger_list_ord,text)\n",
    "    if len(ord_find) > 0:\n",
    "        score_ord = 1\n",
    "        trig_list_ord = ' , '.join(str(n) for n in ord_find )\n",
    "    #Перевод на карту            \n",
    "    trans_find = re.findall(triger_list_transfer,text)    \n",
    "    if len(trans_find) > 0:\n",
    "        score_transfer = 1\n",
    "                \n",
    "    return new_trig_list_pay,new_trig_list_pers, new_score_pay,new_score_pers,trig_list_ord, score_ord, score_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получить все эмейлы их текста\n",
    "def find_all_emails(text):\n",
    "    alphabet = ('АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюя')\n",
    "    emails = re.findall(r'[\\w.-]+@[\\w\\.-]+\\.[\\w\\.]+',text)\n",
    "    emails = list(set(emails))\n",
    "    for i in range(len(emails)):\n",
    "        #Удалить русские буквы \n",
    "        for char in emails[i]:\n",
    "            if char in alphabet:\n",
    "                emails[i] = emails[i].replace(char,'')\n",
    "        #удалить первые и последние точки      \n",
    "        while emails[i][0] == '.':\n",
    "            emails[i] = emails[i][1:]\n",
    "        while emails[i][-1] == '.':\n",
    "            emails[i] = emails[i][:-1]    \n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Првоерить эмейлы \n",
    "def cheсk_email(emailinput):\n",
    "    emailcheck = validate_email(emailinput)  \n",
    "    #print(emailcheck)\n",
    "    if emailcheck:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверка эмейлов и классификация на хорошие и плохие\n",
    "def find_check_emails(text):\n",
    "    emails_start_time = time()\n",
    "    emails_g = ''\n",
    "    emails_b = ''\n",
    "    n_g = 0\n",
    "    n_b = 0\n",
    "    emails_list = []\n",
    "    \n",
    "    for email in find_all_emails(text):\n",
    "        if emails_start_time - time() >= 300:\n",
    "            return 'time','time','time','time'\n",
    "        if not email in list(emails_list):\n",
    "            emails_list.append(email)\n",
    "            cheсk = cheсk_email(email)\n",
    "            \n",
    "            if cheсk:\n",
    "                emails_g += f'{email} , '\n",
    "                n_g += 1\n",
    "            else:\n",
    "                emails_b += f'{email} , '\n",
    "                n_b += 1\n",
    "                \n",
    "    return emails_g,emails_b,n_g,n_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск ИНН\n",
    "INN_re = re.compile(r'\\d{10}|\\d{12}')\n",
    "#ИНН\\x20*\n",
    "df_reestr = pd.read_csv('recheck_urls.csv',index_col = 0)\n",
    "def find_inn(text,URL):\n",
    "    inn_start_time = time()\n",
    "    final = ''\n",
    "    n_inn = 0\n",
    "    inn_list = list(set(INN_re.findall(text)))\n",
    "    same = df_reestr[df_reestr.URL == URL]\n",
    "    INN_list = list(same.INN)\n",
    "    \n",
    "    for i in  INN_list:\n",
    "        if inn_start_time - time() >= 300:\n",
    "            return 'time','time'\n",
    "        i = str(i)\n",
    "        if i in inn_list:\n",
    "            final += f'{i} , '\n",
    "            n_inn +=1\n",
    "\n",
    "    return final, n_inn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Поиск номеров телефонов\n",
    "phone_re = re.compile(r'(\\d{1}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})')\n",
    "# phone_re = re.compile(r\"(?:(?:8|\\+7)[\\- ]?)?(?:\\(?\\d{3}\\)?[\\- ]?)?[\\d\\- ]{7,10}\")\n",
    "# #phone_re = re.compile(r\"((8|\\+7)[\\- ]?)?(\\(?\\d{3}\\)?[\\- ]?)?[\\d\\- ]{7,10}\")\n",
    "# #phone_re = re.compile(r'(?:(?:\\+?1\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?')\n",
    "#phone_re = re.compile(r'\\b\\+?[7,8](\\s*\\d{3}\\s*\\d{3}\\s*\\d{2}\\s*\\d{2})\\b')\n",
    "\n",
    "def find_phone(text):\n",
    "    ph_start_time = time()\n",
    "    num_phone = 0\n",
    "    \n",
    "    text_ph = text.lower()\n",
    "    text_ph = text_ph.replace(' ','')\n",
    "    text_ph = text_ph.replace('(','')\n",
    "    text_ph = text_ph.replace(')','')\n",
    "    text_ph = text_ph.replace('-','')\n",
    "    text_ph = text_ph.replace('+','')\n",
    "    results = ( phone_re.findall(text_ph) )\n",
    "    new_res = ''\n",
    "    results= list(set(results))\n",
    "    for ph in results:\n",
    "        if ph_start_time - time() >= 300:\n",
    "            return 'time','time'\n",
    "        ph = str(ph).replace(' ','')\n",
    "        if len(ph)>=10 and ph[0] in ['7','8']:\n",
    "        #if len(ph) >=5:\n",
    "            new_res += f'{ph} , '\n",
    "            num_phone +=1\n",
    "\n",
    "    return  new_res, num_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Поиск в тексте триггеров авторизации и 404 ошибки\n",
    "login_r = 'логин|пароль|личный кабинет|войти|регистрация|имя пользователя'\n",
    "NotFound_r = '404|not found'\n",
    "  \n",
    "def log_404(text):\n",
    "    log = re.findall(login_r,text)    \n",
    "    if len(log) > 0:\n",
    "        log_s = 1\n",
    "    else:\n",
    "        log_s = 0\n",
    "            \n",
    "    N_F = re.findall(NotFound_r,text)    \n",
    "    if len(N_F) > 0:\n",
    "        N_F_s = 1\n",
    "    else:\n",
    "        N_F_s = 0\n",
    "                        \n",
    "    return log_s, N_F_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Кол-во символов в тексте без пробелов \n",
    "def len_page(text):\n",
    "    text = text.replace(' ','')\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('ALL_02_new_scrchk.csv',index_col = 0,low_memory=False)\n",
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_clear = ['URL_x','name', 'URL_y', 'transfer', 'respons', 'pay', 'pers', 'order',\n",
    "       'contacts', '10KB', 'total', 'LEN', 'LOG', 'NF_404', 'num_char','Status']\n",
    "for col in col_to_clear:  \n",
    "    df_all[col] = np.NaN\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i = 0\n",
    "start_time = time()\n",
    "change = 0\n",
    "\n",
    "df_work = df_recheck.copy()\n",
    "\n",
    "len_df = len(list(df_work.itertuples(index=True, name='Pandas')))\n",
    "\n",
    "ProgBar_all = IntProgress(min=0, max=len_df, value=i)\n",
    "\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0'}\n",
    "\n",
    "for row in df_work.itertuples(index=True, name='Pandas'):\n",
    "    #text = ' '\n",
    "    print(f'i = {i}/{l1}, URL = {row.URL_old}')\n",
    "    ProgBar_all.value = i\n",
    "    display(ProgBar_all)\n",
    "    \n",
    "    new_url, status = cheek_url(row.URL_old)\n",
    "    df_work.loc[row.Index, 'URL_x'] = new_url\n",
    "    df_work.loc[row.Index, 'Status'] = status\n",
    "    if str(status) != '200':\n",
    "        i+=1\n",
    "        continue\n",
    "    df_work.loc[row.Index, 'URL_y'] = new_url\n",
    "    j = 0\n",
    "    list_url = get_all_links(new_url)\n",
    "    list_url.insert(0,new_url)\n",
    "    len_url = len(list_url)\n",
    "    ProgBar_page = IntProgress(min=j, max=len_url, value=j)\n",
    "    \n",
    "    for url in list_url:\n",
    "        ProgBar_page.value = j\n",
    "        if url.endswith('.jpg') or url.endswith('.pdf') or url.endswith('.exe') or url.endswith('.mp4') or url.endswith('.jpeg'):\n",
    "            j+=1\n",
    "            continue\n",
    "        clear_output(True)\n",
    "        print(f'i = {i}/{l1}, URL = {new_url}')\n",
    "        print(f\"page {j} of {len_url}. URL = {url} . Time = {(time() - start_time) // 60}\")\n",
    "        ProgBar_page.value = j\n",
    "        display(ProgBar_page)\n",
    "        j+=1\n",
    "        try:\n",
    "            html = requests.get(url,headers=HEADERS,timeout = 60).text\n",
    "            soup = BS(html)\n",
    "            text =  soup.body.get_text().lower()\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        new_trig_list_pay,new_trig_list_pers, new_score_pay,new_score_pers,trig_list_ord, score_ord, score_transfer = new_find_triggers(text)\n",
    "        log_s, N_F_s = log_404(text)\n",
    "        n_char = len_page(text)\n",
    "        \n",
    "        df_work.loc[row.Index, 'transfer'] = df_work.loc[row.Index, 'transfer'] or score_transfer\n",
    "        df_work.loc[row.Index, 'pay'] = df_work.loc[row.Index, 'pay'] and new_score_pay == 0\n",
    "        df_work.loc[row.Index, 'pers'] = df_work.loc[row.Index, 'pers'] and new_score_pers == 0   \n",
    "        df_work.loc[row.Index, 'order'] = df_work.loc[row.Index, 'order'] and score_ord == 0\n",
    "        \n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['URL_x','name', 'URL_y', 'transfer', 'respons', 'pay', 'pers', 'order',\n",
    "       'contacts', '10KB', 'total', 'LEN', 'LOG', 'NF_404', 'num_char']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
